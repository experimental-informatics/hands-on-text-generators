{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Order random text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Order text generation\n",
    "\n",
    "Pure random choice. Every character is choosen by the same probabilty. No text is used as a base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a list of all characters between A and Z. '''\n",
    "vocab = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Append punctuation and a space. '''\n",
    "for punct in [',', '.', '!', '?', ' ']:\n",
    "    vocab.append(punct)\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a random token from the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(vocab) -1)\n",
    "print(index)\n",
    "vocab[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate zero-order random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = '' # Variable to store our generated text.\n",
    "\n",
    "for i in range(60):\n",
    "    # Get a random index.\n",
    "    index = random.randint(0, len(vocab) - 1)\n",
    "    \n",
    "    # Get the corresponding token.\n",
    "    token = vocab[index]\n",
    "    \n",
    "    # Append it to our generated text.\n",
    "    generated_text += token\n",
    "\n",
    "# Print the generated text after the loop has ended.\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-Order text generation\n",
    "\n",
    "Probabilities are drawn from a text analysis. Characters that appear more often in the text will have a higher probability to be chosen.<br>\n",
    "\n",
    "The easiest method is to simply store all characters in a list.\n",
    "Characters that appear often in the text are more often stored in the list<br>\n",
    "and thus picked more often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Example. '''\n",
    "\n",
    "txt = 'aaabaa'\n",
    "\n",
    "characters = [c for c in txt]\n",
    "print('characters:', characters, '\\n')\n",
    "\n",
    "for i in range(20):\n",
    "    print(random.choice(characters), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of characters contains 5 'a's and only 1 b, so a randomly picked character will be an 'a' most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Frisch, Max. Schwarzes Quadrat. Zwei Poetikvorlesungen. Frankfurt am Main: Suhrkamp, 2008. 73-74. '''\n",
    "\n",
    "txt = '''\n",
    "– Die POESIE ist zweckfrei.\n",
    "(Schon das macht sie zur Irritation.)\n",
    "\n",
    "– Die POESIE muss kein Kabinett bilden, zum Beispiel, und muss nicht von einer analphabetischen Mehrheit gewählt werden.\n",
    "\n",
    "– Die POESIE ist da oder manchmal auch nicht.\n",
    "(Regierungen sind immer da.)\n",
    "\n",
    "– Die POESIE kann ignoriert werden.\n",
    "(Ohne dass die Polizei deswegen eingreift.)\n",
    "\n",
    "– Die POESIE entsteht trotzdem da und dort.\n",
    "\n",
    "– Die POESIE ist der Durchbruch zur genuinen Erfahrung unsrer menschlichen Existenz in ihrer geschichtlichen Bedingtheit. Sie befreit uns zur Spontaneität – was beides sein kann: Glück oder Schrecken.\n",
    "(Regierungen wollen immer nur unser Glück.)\n",
    "\n",
    "– Die POESIE macht uns betroffen.\n",
    "(Lebendig.)\n",
    "\n",
    "– Die POESIE unterwandert unser ideologisiertes Bewusstsein und insofoern ist sie subversiv in jedem gesellschaftlichen System.\n",
    "(Platon hat natürlich recht: der Poet ist als Staatsbürger dubios, auch wenn er seine Steuern zahlt, auch wenn er als Soldat gehorcht, damit er nicht von seinen eignen Leuten erschossen wird; solange er aber nicht erschossen ist, bleibt er ein Poet.)\n",
    "\n",
    "– Die POESIE muss keine Massnahmen ergreifen.\n",
    "(Sie muss nur Poesie sein.)\n",
    "\n",
    "– Die POESIE findet sich nicht ab (im Gegensatz zur Politik) mit dem Machbaren; sie kann nicht lassen von der Trauer, dass das Menschsein auf dieser Erde nicht anders ist.\n",
    "\n",
    "– Die POESIE sagt nicht, wohin mit dem Atom-Müll.\n",
    "(Rezepte sind von ihr nicht zu erwarten.)\n",
    "\n",
    "– Die POESIE ist arrogant.\n",
    "(Sie entzieht sich der Pflicht, die Welt zu regieren.)\n",
    "\n",
    "– Die POESIE ist unbrauchbar.\n",
    "(Es genügt ihr, dass sie da ist: als Ausdruck unseres profunden Ungenügens und unsrer profunden Sehnsucht.)\n",
    "\n",
    "– Die POESIE wahrt die Utopie.\n",
    "'''\n",
    "print(txt[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate first-order random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = [c for c in txt]\n",
    "\n",
    "for i in range(50):\n",
    "    print(random.choice(characters), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-Order text generation\n",
    "\n",
    "The probability of a character depends on its left neighbor.<br>\n",
    "For that we will create a dictionary called 'vocabulary'. For each individual token of our text we will store all next tokens.<br>\n",
    "When we generate our text we will pick a random token of this list as we have done it in the first-order text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a vocabulary.\n",
    "Store for each character all characters that are next to it in a dictionary.'''\n",
    "\n",
    "vocabulary = {}\n",
    "\n",
    "# Loop through the text:\n",
    "for i in range(len(txt) -1): # we add -1 because the last token of our text has no following next token.\n",
    "    \n",
    "    # The current token is the key for our dictionary.\n",
    "    key = txt[i]\n",
    "    \n",
    "    # The next token (i+1) is the corresponding value.\n",
    "    value = txt[i+1]\n",
    "    \n",
    "    # Check if the key exists in the dictionary already.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value to the list.\n",
    "        vocabulary[key].append(value)\n",
    "        \n",
    "    # If not, insert the new key + the value in form of a [list].\n",
    "    else:\n",
    "        vocabulary[key] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Print all options for one character. '''\n",
    "key = 'P'\n",
    "vocabulary[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tokens appear more often than others. Due to that their probability to be chosen is higher than the one for others.<br>\n",
    "If we have a small dataset, the options for a key are limited. In the example above with a 'P' as key the next character can be any of 'O', 'o', 'l' or 'f'.<br>\n",
    "A different token is not possible.\n",
    "\n",
    "Next we write a function, which takes a key (like 'P') as argument and returns one possible next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Return a randomly selected token from our list of options. '''\n",
    "\n",
    "def next_token(key):\n",
    "    \n",
    "    # Get all options stored for in the dictionary for this key.\n",
    "    options = vocabulary[key]\n",
    "    \n",
    "    # Pick one.\n",
    "    choice = random.choice(options)\n",
    "    \n",
    "    # Return this value.\n",
    "    return choice\n",
    "\n",
    "print(next_token('P'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate second-order random text\n",
    "\n",
    "To generate our text we create a variable with some input (at least one key).\n",
    "\n",
    "Then we run a loop. The argument for `range` defines how many tokens we will generate.\n",
    "\n",
    "In each iteration of our loop we call the function `next_token()` and append the returned token to our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Generate text. '''\n",
    "\n",
    "generated_text = '– Die POESIE' # We start with this as input.\n",
    "\n",
    "# The code below is executed 50 times to append 50 characters.\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    # The last token of generated_text is the key to get the next token.\n",
    "    key = generated_text[-1]\n",
    "    \n",
    "    # Pick one token for this key.\n",
    "    choice = next_token(key)\n",
    "    \n",
    "    # Append this token to the generated text.\n",
    "    \n",
    "    generated_text += choice\n",
    "    \n",
    "    \n",
    "    # We could write the code above into one line:\n",
    "#     generated_text += next_token(generated_text[-1])\n",
    "\n",
    "# We print the generated text once when the for-loop has finished.\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Order text generation (3rd and above)\n",
    "\n",
    "In principle this is nothing else than the second-order text generation, except that we take not just one token into account (as key) when we predict the next token.\n",
    "\n",
    "![ngrams.png](images/ngrams.png)\n",
    "\n",
    "Third-Order (n=2) means that we use two tokens as key,<br>\n",
    "Fourth-Order are three tokens (n=3),<br>\n",
    "...\n",
    "\n",
    "We will write a more dynamic code and use a variable `n` to define how many tokens are used as key.<br>\n",
    "Then we can easily change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a vocabulary.\n",
    "Store all n token as key and their next tokens as values. '''\n",
    "\n",
    "n = 2\n",
    "vocabulary = {}\n",
    "\n",
    "for i in range(len(txt) -n): # Now it's important to stop the loop at len() - n.\n",
    "    \n",
    "    # The current token (i) and the next tokens (i+n) are key.\n",
    "    key = txt[i:i+n]\n",
    "    \n",
    "    # The next token after the last token of key is the corresponding value.\n",
    "    value = txt[i+n]\n",
    "    \n",
    "    # First check if the key exists in the dictionary already.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value to the list.\n",
    "        vocabulary[key].append(value)\n",
    "        \n",
    "    # Else insert the new key + the value in form of a [list].\n",
    "    else:\n",
    "        vocabulary[key] = [value]\n",
    "        \n",
    "''' Function to return a randomly selected character from our list of options.\n",
    "This is similar to the function we used above, but we first check if a key exists.\n",
    "If not, we pick a random key of our dictionary. '''\n",
    "\n",
    "def next_token(key):\n",
    "    \n",
    "    # First check if the key is included in the dictionary.\n",
    "    \n",
    "    if not key in vocabulary.keys():        \n",
    "        # If not: pick a random key.\n",
    "        key = random.choice(list(vocabulary.keys()))\n",
    "        \n",
    "    # Get all options for this key.\n",
    "    options = vocabulary[key]\n",
    "    \n",
    "    # Return a random choice of this list.\n",
    "    return random.choice(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: ig\n",
      "options:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['n', '.', 'n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Test: print all options for one key. \n",
    "Make sure that the key has the length defined in n. '''\n",
    "\n",
    "key = random.choice(list(vocabulary.keys()))\n",
    "print('key:', key)\n",
    "print('options:')\n",
    "vocabulary[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Test: pick a random next token. '''\n",
    "next_token(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate n-order random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "– Die POESIE mitistensrensrer Irrie POESIE mal ar.\n",
      "(Es blenügt\n"
     ]
    }
   ],
   "source": [
    "''' Generate text. '''\n",
    "\n",
    "generated_text = '– Die POESIE' # We start with this as input.\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    # The last n token of generated_text is the key to get the next token.\n",
    "    key = generated_text[-n:]\n",
    "    \n",
    "    # Pick one token for this key.\n",
    "    choice = next_token(key)\n",
    "    \n",
    "    # Append this token to the generated text.\n",
    "    \n",
    "    generated_text += choice\n",
    "    \n",
    "    # The code above as one line:\n",
    "#     generated_text += next_token(generated_text[-n:])\n",
    "    \n",
    "# We print the generated text once when the for-loop has finished.\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Order text generation with probability table\n",
    "\n",
    "(This is also similar to the code above, but creates a probability table to chose from instead of a list with all possible tokens (in multiple occurences).)\n",
    "\n",
    "For an introduction into this, have a look at the last part of [this Notebook](https://github.com/experimental-informatics/hands-on-python/blob/master/dictionary_list.ipynb) about lists and dictionaries.\n",
    "\n",
    "*This Method might result in the same as working without a probability table, since the distribution is already implied.*\n",
    "\n",
    "*But once we work on a more complex and longer text, this method will be more efficient and reduce time complexity.*\n",
    "\n",
    "\n",
    "\n",
    "Keep in mind every single token may have more than one possible next token. \n",
    "\n",
    "So we need to create a `nested dictionary` to store probability values.\n",
    "\n",
    "It might looks like this, having a `dictionary` in a `dictionary`.\n",
    "\n",
    "\n",
    "```python\n",
    "{\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    'ei' : {'n': 0.75, 'g': 0.25}\n",
    "    'en' : {'t': 1.0}\n",
    "    'er' : {' ': 0.5555, 's': 0.2222, 'g': 0.1111, 'w': 0.1111}\n",
    "    'fi' : {'n': 1.0}\n",
    "    'ge' : {'w': 0.1666, 'n': 0.3333, 's': 0.3333, 'h': 0.1666}\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "}\n",
    "```\n",
    "\n",
    "All probability values for one key sum up to 1 (100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "– {' ': 1.0}\n",
      "\n",
      "(E {'s': 1.0}\n",
      "\n",
      "(L {'e': 1.0}\n",
      "\n",
      "(O {'h': 1.0}\n",
      "\n",
      "(P {'l': 1.0}\n",
      "\n",
      "(R {'e': 1.0}\n",
      "\n",
      "(S {'c': 0.3333333333333333, 'i': 0.6666666666666666}\n",
      "\n",
      "–  {'D': 1.0}\n",
      " (i {'m': 1.0}\n",
      " At {'o': 1.0}\n",
      " Au {'s': 1.0}\n",
      " Be {'i': 0.3333333333333333, 'd': 0.3333333333333333, 'w': 0.3333333333333333}\n",
      " Di {'e': 1.0}\n",
      " Du {'r': 1.0}\n",
      " Er {'f': 0.5, 'd': 0.5}\n",
      " Ex {'i': 1.0}\n",
      " Ge {'g': 1.0}\n",
      " Gl {'ü': 1.0}\n",
      " Ir {'r': 1.0}\n",
      " Ka {'b': 1.0}\n",
      " Le {'u': 1.0}\n",
      " Ma {'s': 0.5, 'c': 0.5}\n",
      " Me {'h': 0.5, 'n': 0.5}\n",
      " PO {'E': 1.0}\n",
      " Pf {'l': 1.0}\n",
      " Po {'l': 0.4, 'e': 0.6}\n",
      " Sc {'h': 1.0}\n",
      " Se {'h': 1.0}\n",
      " Si {'e': 1.0}\n",
      " So {'l': 1.0}\n",
      " Sp {'o': 1.0}\n",
      " St {'a': 0.5, 'e': 0.5}\n",
      " Sy {'s': 1.0}\n",
      " Tr {'a': 1.0}\n",
      " Un {'g': 1.0}\n",
      " Ut {'o': 1.0}\n",
      " We {'l': 1.0}\n",
      " ab {'e': 0.5, ' ': 0.5}\n",
      " al {'s': 1.0}\n",
      " an {'a': 0.5, 'd': 0.5}\n",
      " ar {'r': 1.0}\n",
      " au {'c': 0.75, 'f': 0.25}\n",
      " be {'f': 0.3333333333333333, 'i': 0.3333333333333333, 't': 0.3333333333333333}\n",
      " bi {'l': 1.0}\n",
      " bl {'e': 1.0}\n",
      " da {'s': 0.5, ' ': 0.3, '.': 0.1, 'm': 0.1}\n",
      " de {'s': 0.14285714285714285, 'r': 0.5714285714285714, 'm': 0.2857142857142857}\n",
      " di {'e': 1.0}\n",
      " do {'r': 1.0}\n",
      " du {'b': 1.0}\n",
      " ei {'n': 0.75, 'g': 0.25}\n",
      " en {'t': 1.0}\n",
      " er {' ': 0.5555555555555556, 's': 0.2222222222222222, 'g': 0.1111111111111111, 'w': 0.1111111111111111}\n",
      " fi {'n': 1.0}\n",
      " ge {'w': 0.16666666666666666, 'n': 0.3333333333333333, 's': 0.3333333333333333, 'h': 0.16666666666666666}\n",
      " ha {'t': 1.0}\n",
      " id {'e': 1.0}\n",
      " ig {'n': 1.0}\n",
      " ih {'r': 1.0}\n",
      " im {'m': 1.0}\n",
      " in {' ': 0.6666666666666666, 's': 0.3333333333333333}\n",
      " is {'t': 1.0}\n",
      " je {'d': 1.0}\n",
      " ka {'n': 1.0}\n",
      " ke {'i': 1.0}\n",
      " la {'s': 1.0}\n",
      " ma {'c': 0.6666666666666666, 'n': 0.3333333333333333}\n",
      " me {'n': 1.0}\n",
      " mi {'t': 1.0}\n",
      " mu {'s': 1.0}\n",
      " na {'t': 1.0}\n",
      " ni {'c': 1.0}\n",
      " nu {'r': 1.0}\n",
      " od {'e': 1.0}\n",
      " pr {'o': 1.0}\n",
      " re {'c': 0.5, 'g': 0.5}\n",
      " sa {'g': 1.0}\n",
      " se {'i': 1.0}\n",
      " si {'e': 0.5, 'n': 0.25, 'c': 0.25}\n",
      " so {'l': 1.0}\n",
      " su {'b': 1.0}\n",
      " tr {'o': 1.0}\n",
      " un {'d': 0.3076923076923077, 's': 0.5384615384615384, 't': 0.07692307692307693, 'b': 0.07692307692307693}\n",
      " vo {'n': 1.0}\n",
      " wa {'s': 0.5, 'h': 0.5}\n",
      " we {'r': 0.5, 'n': 0.5}\n",
      " wi {'r': 1.0}\n",
      " wo {'l': 0.5, 'h': 0.5}\n",
      " za {'h': 1.0}\n",
      " zu {'r': 0.5714285714285714, 'm': 0.14285714285714285, ' ': 0.2857142857142857}\n",
      " zw {'e': 1.0}\n",
      " –  {'w': 1.0}\n",
      "(Es {' ': 1.0}\n",
      "(Le {'b': 1.0}\n",
      "(Oh {'n': 1.0}\n",
      "(Pl {'a': 1.0}\n",
      "(Re {'g': 0.6666666666666666, 'z': 0.3333333333333333}\n",
      "(Sc {'h': 1.0}\n",
      "(Si {'e': 1.0}\n",
      "(im {' ': 1.0}\n",
      ")\n",
      "\n",
      " {'–': 1.0}\n",
      ") m {'i': 1.0}\n",
      ", a {'u': 1.0}\n",
      ", b {'l': 1.0}\n",
      ", d {'a': 0.75, 'i': 0.25}\n",
      ", u {'n': 1.0}\n",
      ", w {'o': 1.0}\n",
      ", z {'u': 1.0}\n",
      "-Mü {'l': 1.0}\n",
      ".\n",
      "\n",
      " {'–': 1.0}\n",
      ".\n",
      "( {'S': 0.3, 'R': 0.3, 'O': 0.1, 'L': 0.1, 'P': 0.1, 'E': 0.1}\n",
      ". S {'i': 1.0}\n",
      ".)\n",
      " {'\\n': 1.0}\n",
      ": G {'l': 1.0}\n",
      ": a {'l': 1.0}\n",
      ": d {'e': 1.0}\n",
      "; s {'o': 0.5, 'i': 0.5}\n",
      "Ato {'m': 1.0}\n",
      "Aus {'d': 1.0}\n",
      "Bed {'i': 1.0}\n",
      "Bei {'s': 1.0}\n",
      "Bew {'u': 1.0}\n",
      "Die {' ': 1.0}\n",
      "Dur {'c': 1.0}\n",
      "E e {'n': 1.0}\n",
      "E f {'i': 1.0}\n",
      "E i {'s': 1.0}\n",
      "E k {'a': 1.0}\n",
      "E m {'u': 0.6666666666666666, 'a': 0.3333333333333333}\n",
      "E s {'a': 1.0}\n",
      "E u {'n': 1.0}\n",
      "E w {'a': 1.0}\n",
      "ESI {'E': 1.0}\n",
      "Erd {'e': 1.0}\n",
      "Erf {'a': 1.0}\n",
      "Es  {'g': 1.0}\n",
      "Exi {'s': 1.0}\n",
      "Geg {'e': 1.0}\n",
      "Glü {'c': 1.0}\n",
      "IE  {'i': 0.35714285714285715, 'm': 0.21428571428571427, 'k': 0.07142857142857142, 'e': 0.07142857142857142, 'u': 0.07142857142857142, 'f': 0.07142857142857142, 's': 0.07142857142857142, 'w': 0.07142857142857142}\n",
      "Irr {'i': 1.0}\n",
      "Kab {'i': 1.0}\n",
      "Leb {'e': 1.0}\n",
      "Leu {'t': 1.0}\n",
      "Mac {'h': 1.0}\n",
      "Mas {'s': 1.0}\n",
      "Meh {'r': 1.0}\n",
      "Men {'s': 1.0}\n",
      "Mül {'l': 1.0}\n",
      "OES {'I': 1.0}\n",
      "Ohn {'e': 1.0}\n",
      "POE {'S': 1.0}\n",
      "Pfl {'i': 1.0}\n",
      "Pla {'t': 1.0}\n",
      "Poe {'t': 0.6666666666666666, 's': 0.3333333333333333}\n",
      "Pol {'i': 1.0}\n",
      "Reg {'i': 1.0}\n",
      "Rez {'e': 1.0}\n",
      "SIE {' ': 1.0}\n",
      "Sch {'o': 0.5, 'r': 0.5}\n",
      "Seh {'n': 1.0}\n",
      "Sie {' ': 1.0}\n",
      "Sol {'d': 1.0}\n",
      "Spo {'n': 1.0}\n",
      "Sta {'a': 1.0}\n",
      "Ste {'u': 1.0}\n",
      "Sys {'t': 1.0}\n",
      "Tra {'u': 1.0}\n",
      "Ung {'e': 1.0}\n",
      "Uto {'p': 1.0}\n",
      "Wel {'t': 1.0}\n",
      "a i {'s': 1.0}\n",
      "a o {'d': 1.0}\n",
      "a u {'n': 1.0}\n",
      "a.) {'\\n': 1.0}\n",
      "aat {'s': 1.0}\n",
      "ab  {'(': 1.0}\n",
      "abe {'t': 0.5, 'r': 0.5}\n",
      "abi {'n': 1.0}\n",
      "ach {'t': 0.6666666666666666, 'b': 0.3333333333333333}\n",
      "aft {'l': 1.0}\n",
      "agt {' ': 1.0}\n",
      "ahl {'t': 1.0}\n",
      "ahm {'e': 1.0}\n",
      "ahr {'u': 0.5, 't': 0.5}\n",
      "al  {'a': 1.0}\n",
      "alp {'h': 1.0}\n",
      "als {' ': 1.0}\n",
      "ami {'t': 1.0}\n",
      "ana {'l': 1.0}\n",
      "anc {'h': 1.0}\n",
      "and {'e': 1.0}\n",
      "ane {'i': 1.0}\n",
      "ang {'e': 1.0}\n",
      "ann {' ': 0.6666666666666666, ':': 0.3333333333333333}\n",
      "ant {'.': 1.0}\n",
      "ar. {'\\n': 1.0}\n",
      "are {'n': 1.0}\n",
      "arr {'o': 1.0}\n",
      "art {'e': 1.0}\n",
      "as  {'m': 0.3333333333333333, 'b': 0.3333333333333333, 'M': 0.3333333333333333}\n",
      "ass {' ': 0.6, 'n': 0.2, 'e': 0.2}\n",
      "at  {'n': 0.5, 'g': 0.5}\n",
      "ati {'o': 1.0}\n",
      "ato {'n': 1.0}\n",
      "ats {'b': 1.0}\n",
      "atz {' ': 1.0}\n",
      "atü {'r': 1.0}\n",
      "auc {'h': 1.0}\n",
      "aue {'r': 1.0}\n",
      "auf {' ': 1.0}\n",
      "b ( {'i': 1.0}\n",
      "bar {'e': 0.5, '.': 0.5}\n",
      "bef {'r': 1.0}\n",
      "bei {'d': 1.0}\n",
      "ben {'d': 1.0}\n",
      "ber {' ': 1.0}\n",
      "bet {'i': 0.5, 'r': 0.5}\n",
      "bil {'d': 1.0}\n",
      "bin {'e': 1.0}\n",
      "bio {'s': 1.0}\n",
      "ble {'i': 1.0}\n",
      "bra {'u': 1.0}\n",
      "bru {'c': 1.0}\n",
      "bt  {'e': 1.0}\n",
      "bve {'r': 1.0}\n",
      "bür {'g': 1.0}\n",
      "ch  {'n': 0.2857142857142857, 'z': 0.14285714285714285, 'r': 0.14285714285714285, 'w': 0.2857142857142857, 'd': 0.14285714285714285}\n",
      "cha {'f': 1.0}\n",
      "chb {'r': 0.3333333333333333, 'a': 0.6666666666666666}\n",
      "che {'n': 1.0}\n",
      "chi {'c': 1.0}\n",
      "chl {'i': 1.0}\n",
      "chm {'a': 1.0}\n",
      "cho {'n': 0.3333333333333333, 's': 0.6666666666666666}\n",
      "chr {'e': 1.0}\n",
      "chs {'e': 1.0}\n",
      "cht {' ': 0.5625, '.': 0.125, 'l': 0.0625, ':': 0.0625, ',': 0.1875}\n",
      "ck  {'o': 0.5, 'u': 0.5}\n",
      "ck. {')': 1.0}\n",
      "cke {'n': 1.0}\n",
      "ckf {'r': 1.0}\n",
      "d d {'o': 1.0}\n",
      "d i {'m': 0.5, 'n': 0.5}\n",
      "d m {'u': 1.0}\n",
      "d u {'n': 1.0}\n",
      "d v {'o': 1.0}\n",
      "d;  {'s': 1.0}\n",
      "da  {'o': 0.3333333333333333, 'u': 0.3333333333333333, 'i': 0.3333333333333333}\n",
      "da. {')': 1.0}\n",
      "dam {'i': 1.0}\n",
      "das {' ': 0.4, 's': 0.6}\n",
      "dat {' ': 1.0}\n",
      "de  {'n': 1.0}\n",
      "dem {' ': 1.0}\n",
      "den {',': 0.2, '.': 0.4, ' ': 0.4}\n",
      "deo {'l': 1.0}\n",
      "der {' ': 0.75, 't': 0.125, 's': 0.125}\n",
      "des {'w': 0.5, ' ': 0.5}\n",
      "det {' ': 1.0}\n",
      "die {' ': 0.75, 's': 0.25}\n",
      "dig {'.': 1.0}\n",
      "din {'g': 1.0}\n",
      "dor {'t': 1.0}\n",
      "dru {'c': 1.0}\n",
      "dub {'i': 1.0}\n",
      "e M {'a': 1.0}\n",
      "e P {'O': 0.9333333333333333, 'o': 0.06666666666666667}\n",
      "e S {'t': 1.0}\n",
      "e U {'t': 1.0}\n",
      "e W {'e': 1.0}\n",
      "e b {'e': 1.0}\n",
      "e d {'a': 1.0}\n",
      "e e {'r': 0.5, 'n': 0.5}\n",
      "e k {'a': 1.0}\n",
      "e m {'u': 1.0}\n",
      "e n {'i': 1.0}\n",
      "e s {'u': 0.3333333333333333, 'e': 0.3333333333333333, 'i': 0.3333333333333333}\n",
      "e z {'u': 1.0}\n",
      "ebe {'n': 1.0}\n",
      "ech {'t': 1.0}\n",
      "eck {'f': 0.5, 'e': 0.5}\n",
      "ede {'m': 1.0}\n",
      "edi {'n': 1.0}\n",
      "efr {'e': 1.0}\n",
      "ege {'n': 1.0}\n",
      "egi {'e': 1.0}\n",
      "ehn {'s': 1.0}\n",
      "eho {'r': 1.0}\n",
      "ehr {'h': 1.0}\n",
      "eht {' ': 1.0}\n",
      "ei  {'d': 1.0}\n",
      "ei. {'\\n': 1.0}\n",
      "eib {'t': 1.0}\n",
      "eid {'e': 1.0}\n",
      "eif {'t': 0.5, 'e': 0.5}\n",
      "eig {'n': 1.0}\n",
      "ein {' ': 0.45454545454545453, 'e': 0.36363636363636365, 'g': 0.09090909090909091, '.': 0.09090909090909091}\n",
      "eis {'p': 1.0}\n",
      "eit {' ': 0.5, '.': 0.25, 'ä': 0.25}\n",
      "el, {' ': 1.0}\n",
      "ell {'s': 1.0}\n",
      "elt {' ': 1.0}\n",
      "em  {'d': 0.25, 'g': 0.25, 'M': 0.25, 'A': 0.25}\n",
      "em. {'\\n': 1.0}\n",
      "en  {'M': 0.05555555555555555, 's': 0.05555555555555555, 'e': 0.2222222222222222, 'E': 0.1111111111111111, 'B': 0.05555555555555555, 'w': 0.1111111111111111, 'i': 0.1111111111111111, 'S': 0.1111111111111111, 'L': 0.05555555555555555, 'v': 0.05555555555555555, 'U': 0.05555555555555555}\n",
      "en, {' ': 1.0}\n",
      "en. {'\\n': 0.7142857142857143, ')': 0.2857142857142857}\n",
      "en; {' ': 1.0}\n",
      "end {'i': 1.0}\n",
      "enn {' ': 1.0}\n",
      "ens {'c': 0.5, 'a': 0.25, ' ': 0.25}\n",
      "ent {'s': 0.5, 'z': 0.5}\n",
      "enu {'i': 1.0}\n",
      "enz {' ': 1.0}\n",
      "enü {'g': 1.0}\n",
      "eol {'o': 1.0}\n",
      "ept {'e': 1.0}\n",
      "er  {'a': 0.13636363636363635, 'm': 0.09090909090909091, 'd': 0.09090909090909091, 'D': 0.045454545454545456, 'g': 0.045454545454545456, 'S': 0.045454545454545456, 'n': 0.13636363636363635, 'G': 0.045454545454545456, 'i': 0.045454545454545456, 'P': 0.09090909090909091, 's': 0.045454545454545456, 'e': 0.045454545454545456, 'T': 0.045454545454545456, 'E': 0.045454545454545456, 'p': 0.045454545454545456}\n",
      "er, {' ': 1.0}\n",
      "erd {'e': 1.0}\n",
      "ere {'n': 0.5, 's': 0.5}\n",
      "erg {'r': 1.0}\n",
      "ern {' ': 1.0}\n",
      "ers {'i': 0.25, 'c': 0.5, ' ': 0.25}\n",
      "ert {' ': 0.6666666666666666, 'e': 0.3333333333333333}\n",
      "eru {'n': 1.0}\n",
      "erw {'a': 1.0}\n",
      "es  {'s': 0.3333333333333333, 'B': 0.3333333333333333, 'p': 0.3333333333333333}\n",
      "esc {'h': 1.0}\n",
      "ese {'l': 0.5, 'r': 0.5}\n",
      "esi {'e': 1.0}\n",
      "esw {'e': 1.0}\n",
      "et  {'i': 0.5, 's': 0.5}\n",
      "et. {')': 1.0}\n",
      "eti {'s': 1.0}\n",
      "etr {'o': 1.0}\n",
      "ett {' ': 1.0}\n",
      "eue {'r': 1.0}\n",
      "eut {'e': 1.0}\n",
      "ewu {'s': 1.0}\n",
      "ewä {'h': 1.0}\n",
      "eze {'p': 1.0}\n",
      "f d {'i': 1.0}\n",
      "fah {'r': 1.0}\n",
      "fen {'.': 1.0}\n",
      "ffe {'n': 1.0}\n",
      "fin {'d': 1.0}\n",
      "fli {'c': 1.0}\n",
      "foe {'r': 1.0}\n",
      "fre {'i': 1.0}\n",
      "ft. {')': 1.0}\n",
      "ftl {'i': 1.0}\n",
      "fun {'d': 1.0}\n",
      "g u {'n': 1.0}\n",
      "g.) {'\\n': 1.0}\n",
      "gan {'t': 1.0}\n",
      "ge  {'e': 1.0}\n",
      "geh {'o': 1.0}\n",
      "gen {' ': 0.375, 'u': 0.125, 's': 0.25, 'ü': 0.25}\n",
      "ger {' ': 1.0}\n",
      "ges {'c': 0.5, 'e': 0.5}\n",
      "gew {'ä': 1.0}\n",
      "gie {'r': 1.0}\n",
      "gis {'i': 1.0}\n",
      "gne {'n': 1.0}\n",
      "gno {'r': 1.0}\n",
      "gre {'i': 1.0}\n",
      "gt  {'n': 0.5, 'i': 0.5}\n",
      "gth {'e': 1.0}\n",
      "h d {'e': 1.0}\n",
      "h n {'i': 1.0}\n",
      "h r {'e': 1.0}\n",
      "h w {'e': 1.0}\n",
      "h z {'u': 1.0}\n",
      "hab {'e': 1.0}\n",
      "haf {'t': 1.0}\n",
      "hat {' ': 1.0}\n",
      "hba {'r': 1.0}\n",
      "hbr {'u': 1.0}\n",
      "hei {'t': 1.0}\n",
      "hen {' ': 1.0}\n",
      "hic {'h': 1.0}\n",
      "hin {' ': 1.0}\n",
      "hli {'c': 1.0}\n",
      "hlt {' ': 0.5, ',': 0.5}\n",
      "hma {'l': 1.0}\n",
      "hme {'n': 1.0}\n",
      "hne {' ': 1.0}\n",
      "hns {'u': 1.0}\n",
      "hon {' ': 1.0}\n",
      "hor {'c': 1.0}\n",
      "hos {'s': 1.0}\n",
      "hr  {'n': 1.0}\n",
      "hr, {' ': 1.0}\n",
      "hre {'r': 0.5, 'c': 0.5}\n",
      "hrh {'e': 1.0}\n",
      "hrt {' ': 1.0}\n",
      "hru {'n': 1.0}\n",
      "hse {'i': 1.0}\n",
      "ht  {'s': 0.18181818181818182, 'v': 0.18181818181818182, 't': 0.09090909090909091, 'u': 0.09090909090909091, 'e': 0.09090909090909091, 'a': 0.18181818181818182, 'l': 0.09090909090909091, 'z': 0.09090909090909091}\n",
      "ht, {' ': 1.0}\n",
      "ht. {'\\n': 0.5, ')': 0.5}\n",
      "ht: {' ': 1.0}\n",
      "htl {'i': 1.0}\n",
      "i d {'e': 1.0}\n",
      "i.\n",
      " {'(': 1.0}\n",
      "ibt {' ': 1.0}\n",
      "ich {'t': 0.6470588235294118, 'e': 0.17647058823529413, ' ': 0.17647058823529413}\n",
      "ide {'s': 0.5, 'o': 0.5}\n",
      "ie  {'P': 0.6, 'z': 0.04, 'b': 0.04, 's': 0.08, 'm': 0.04, 'k': 0.04, 'e': 0.04, 'W': 0.04, 'd': 0.04, 'U': 0.04}\n",
      "ie. {'\\n': 1.0}\n",
      "ieh {'t': 1.0}\n",
      "iel {',': 1.0}\n",
      "ier {'u': 0.4, 't': 0.4, 'e': 0.2}\n",
      "ies {'e': 1.0}\n",
      "ife {'n': 1.0}\n",
      "ift {'.': 1.0}\n",
      "ig. {')': 1.0}\n",
      "ign {'o': 0.5, 'e': 0.5}\n",
      "ihr {'e': 0.3333333333333333, ' ': 0.3333333333333333, ',': 0.3333333333333333}\n",
      "ik) {' ': 1.0}\n",
      "ild {'e': 1.0}\n",
      "im  {'G': 1.0}\n",
      "imm {'e': 1.0}\n",
      "in  {'K': 0.125, 'i': 0.125, 'k': 0.125, 'u': 0.125, 'j': 0.125, 'P': 0.125, 'a': 0.125, 'm': 0.125}\n",
      "in. {')': 1.0}\n",
      "ind {' ': 0.6666666666666666, 'e': 0.3333333333333333}\n",
      "ine {'t': 0.16666666666666666, 'r': 0.16666666666666666, 'n': 0.3333333333333333, ' ': 0.3333333333333333}\n",
      "ing {'r': 0.5, 't': 0.5}\n",
      "ins {'o': 1.0}\n",
      "ion {'.': 1.0}\n",
      "ios {',': 1.0}\n",
      "ird {';': 1.0}\n",
      "isc {'h': 1.0}\n",
      "isi {'e': 1.0}\n",
      "isp {'i': 1.0}\n",
      "ist {' ': 0.6363636363636364, 'e': 0.09090909090909091, ',': 0.09090909090909091, '.': 0.09090909090909091, ':': 0.09090909090909091}\n",
      "it  {'g': 0.2, 'u': 0.2, 'e': 0.2, 'd': 0.4}\n",
      "it. {' ': 1.0}\n",
      "ita {'t': 1.0}\n",
      "iti {'k': 1.0}\n",
      "itä {'t': 1.0}\n",
      "iv  {'i': 1.0}\n",
      "ize {'i': 1.0}\n",
      "jed {'e': 1.0}\n",
      "k o {'d': 1.0}\n",
      "k u {'n': 1.0}\n",
      "k)  {'m': 1.0}\n",
      "k.) {'\\n': 1.0}\n",
      "kan {'n': 1.0}\n",
      "kei {'n': 1.0}\n",
      "ken {'.': 1.0}\n",
      "kfr {'e': 1.0}\n",
      "l a {'u': 1.0}\n",
      "l,  {'u': 1.0}\n",
      "l.\n",
      " {'(': 1.0}\n",
      "lan {'g': 1.0}\n",
      "las {'s': 1.0}\n",
      "lat {'o': 1.0}\n",
      "lda {'t': 1.0}\n",
      "lde {'n': 1.0}\n",
      "lei {'b': 1.0}\n",
      "len {' ': 1.0}\n",
      "lic {'h': 1.0}\n",
      "lit {'i': 1.0}\n",
      "liz {'e': 1.0}\n",
      "ll. {'\\n': 1.0}\n",
      "lle {'n': 1.0}\n",
      "lls {'c': 1.0}\n",
      "log {'i': 1.0}\n",
      "lph {'a': 1.0}\n",
      "ls  {'S': 0.6666666666666666, 'A': 0.3333333333333333}\n",
      "lsc {'h': 1.0}\n",
      "lt  {'w': 0.5, 'z': 0.5}\n",
      "lt, {' ': 1.0}\n",
      "lüc {'k': 1.0}\n",
      "m A {'t': 1.0}\n",
      "m B {'e': 1.0}\n",
      "m G {'e': 1.0}\n",
      "m M {'a': 1.0}\n",
      "m d {'a': 1.0}\n",
      "m g {'e': 1.0}\n",
      "m-M {'ü': 1.0}\n",
      "m.\n",
      " {'(': 1.0}\n",
      "mac {'h': 1.0}\n",
      "mal {' ': 1.0}\n",
      "man {'c': 1.0}\n",
      "men {'s': 0.5, ' ': 0.5}\n",
      "mer {' ': 1.0}\n",
      "mit {' ': 1.0}\n",
      "mme {'r': 1.0}\n",
      "mus {'s': 1.0}\n",
      "n B {'e': 1.0}\n",
      "n E {'r': 0.5, 'x': 0.5}\n",
      "n K {'a': 1.0}\n",
      "n L {'e': 1.0}\n",
      "n M {'e': 1.0}\n",
      "n P {'o': 1.0}\n",
      "n S {'y': 0.5, 'e': 0.5}\n",
      "n U {'n': 1.0}\n",
      "n a {'u': 1.0}\n",
      "n d {'a': 0.5, 'e': 0.5}\n",
      "n e {'i': 0.42857142857142855, 'r': 0.5714285714285714}\n",
      "n h {'a': 1.0}\n",
      "n i {'g': 0.16666666666666666, 'h': 0.3333333333333333, 'm': 0.16666666666666666, 's': 0.3333333333333333}\n",
      "n j {'e': 1.0}\n",
      "n k {'a': 1.0}\n",
      "n m {'i': 1.0}\n",
      "n n {'i': 1.0}\n",
      "n s {'i': 0.5, 'e': 0.5}\n",
      "n u {'n': 1.0}\n",
      "n v {'o': 1.0}\n",
      "n w {'o': 0.5, 'i': 0.5}\n",
      "n z {'a': 1.0}\n",
      "n,  {'z': 1.0}\n",
      "n.\n",
      " {'\\n': 0.2, '(': 0.8}\n",
      "n.) {'\\n': 1.0}\n",
      "n:  {'G': 1.0}\n",
      "n;  {'s': 1.0}\n",
      "nah {'m': 1.0}\n",
      "nal {'p': 1.0}\n",
      "nat {'ü': 1.0}\n",
      "nbr {'a': 1.0}\n",
      "nch {'m': 1.0}\n",
      "nd  {'m': 0.16666666666666666, 'i': 0.3333333333333333, 'd': 0.16666666666666666, 'v': 0.16666666666666666, 'u': 0.16666666666666666}\n",
      "nde {'r': 0.4, 't': 0.2, 'n': 0.4}\n",
      "ndi {'g': 1.0}\n",
      "ne  {'d': 0.3333333333333333, 'S': 0.3333333333333333, 'M': 0.3333333333333333}\n",
      "nei {'t': 1.0}\n",
      "nen {' ': 1.0}\n",
      "ner {' ': 1.0}\n",
      "net {'t': 1.0}\n",
      "ng  {'u': 1.0}\n",
      "nge {'n': 0.75, ' ': 0.25}\n",
      "ngr {'e': 1.0}\n",
      "ngt {'h': 1.0}\n",
      "nic {'h': 1.0}\n",
      "nn  {'i': 0.25, 'e': 0.5, 'n': 0.25}\n",
      "nn: {' ': 1.0}\n",
      "nor {'i': 1.0}\n",
      "ns  {'z': 0.3333333333333333, 'b': 0.3333333333333333, 'u': 0.3333333333333333}\n",
      "nsa {'t': 1.0}\n",
      "nsc {'h': 1.0}\n",
      "nse {'r': 1.0}\n",
      "nso {'f': 1.0}\n",
      "nsr {'e': 1.0}\n",
      "nsu {'c': 1.0}\n",
      "nt. {'\\n': 1.0}\n",
      "nta {'n': 1.0}\n",
      "nte {'r': 1.0}\n",
      "nts {'t': 1.0}\n",
      "ntz {'i': 1.0}\n",
      "nui {'n': 1.0}\n",
      "nur {' ': 1.0}\n",
      "nz  {'i': 1.0}\n",
      "nüg {'t': 0.5, 'e': 0.5}\n",
      "ode {'r': 1.0}\n",
      "oer {'n': 1.0}\n",
      "oes {'i': 1.0}\n",
      "oet {' ': 0.5, '.': 0.5}\n",
      "off {'e': 1.0}\n",
      "ofo {'e': 1.0}\n",
      "ofu {'n': 1.0}\n",
      "oga {'n': 1.0}\n",
      "ogi {'s': 1.0}\n",
      "ohi {'n': 1.0}\n",
      "ola {'n': 1.0}\n",
      "old {'a': 1.0}\n",
      "oli {'z': 0.5, 't': 0.5}\n",
      "oll {'e': 1.0}\n",
      "olo {'g': 1.0}\n",
      "om- {'M': 1.0}\n",
      "on  {'d': 0.3333333333333333, 'e': 0.16666666666666666, 'h': 0.16666666666666666, 's': 0.16666666666666666, 'i': 0.16666666666666666}\n",
      "on. {')': 1.0}\n",
      "ont {'a': 1.0}\n",
      "opi {'e': 1.0}\n",
      "orc {'h': 1.0}\n",
      "ori {'e': 1.0}\n",
      "ort {'.': 1.0}\n",
      "os, {' ': 1.0}\n",
      "oss {'e': 1.0}\n",
      "otz {'d': 1.0}\n",
      "pha {'b': 1.0}\n",
      "pie {'l': 0.5, '.': 0.5}\n",
      "pon {'t': 1.0}\n",
      "pro {'f': 1.0}\n",
      "pte {' ': 1.0}\n",
      "r D {'u': 1.0}\n",
      "r E {'r': 1.0}\n",
      "r G {'l': 1.0}\n",
      "r I {'r': 1.0}\n",
      "r P {'o': 0.75, 'f': 0.25}\n",
      "r S {'p': 0.5, 'c': 0.5}\n",
      "r T {'r': 1.0}\n",
      "r a {'n': 0.3333333333333333, 'l': 0.3333333333333333, 'b': 0.3333333333333333}\n",
      "r d {'a': 0.5, 'u': 0.5}\n",
      "r e {'i': 1.0}\n",
      "r g {'e': 1.0}\n",
      "r i {'d': 1.0}\n",
      "r m {'a': 0.5, 'e': 0.5}\n",
      "r n {'u': 0.25, 'i': 0.75}\n",
      "r p {'r': 1.0}\n",
      "r s {'e': 1.0}\n",
      "r u {'n': 1.0}\n",
      "r,  {'d': 1.0}\n",
      "r.\n",
      " {'(': 1.0}\n",
      "rau {'e': 0.5, 'c': 0.5}\n",
      "rch {'b': 0.5, 't': 0.5}\n",
      "rd; {' ': 1.0}\n",
      "rde {'n': 0.6666666666666666, ' ': 0.3333333333333333}\n",
      "rec {'k': 0.5, 'h': 0.5}\n",
      "reg {'i': 1.0}\n",
      "rei {'.': 0.25, 'f': 0.5, 't': 0.25}\n",
      "ren {';': 0.5, '.': 0.5}\n",
      "rer {' ': 1.0}\n",
      "res {' ': 1.0}\n",
      "rfa {'h': 1.0}\n",
      "rge {'r': 1.0}\n",
      "rgr {'e': 1.0}\n",
      "rhe {'i': 1.0}\n",
      "rie {'r': 1.0}\n",
      "rit {'a': 1.0}\n",
      "rli {'c': 1.0}\n",
      "rn  {'i': 0.5, 'z': 0.5}\n",
      "rof {'f': 0.3333333333333333, 'u': 0.6666666666666666}\n",
      "rog {'a': 1.0}\n",
      "rot {'z': 1.0}\n",
      "rri {'t': 1.0}\n",
      "rro {'g': 1.0}\n",
      "rs  {'i': 1.0}\n",
      "rsc {'h': 1.0}\n",
      "rsi {'v': 1.0}\n",
      "rt  {'w': 0.3333333333333333, 'u': 0.3333333333333333, 'd': 0.3333333333333333}\n",
      "rt. {'\\n': 1.0}\n",
      "rte {'s': 0.5, 'n': 0.5}\n",
      "ruc {'h': 0.5, 'k': 0.5}\n",
      "run {'g': 1.0}\n",
      "rwa {'n': 0.5, 'r': 0.5}\n",
      "s A {'u': 1.0}\n",
      "s B {'e': 1.0}\n",
      "s M {'e': 1.0}\n",
      "s S {'t': 0.5, 'o': 0.5}\n",
      "s b {'e': 1.0}\n",
      "s d {'i': 0.5, 'a': 0.5}\n",
      "s g {'e': 1.0}\n",
      "s i {'s': 1.0}\n",
      "s k {'e': 1.0}\n",
      "s m {'a': 1.0}\n",
      "s n {'i': 0.5, 'u': 0.5}\n",
      "s p {'r': 1.0}\n",
      "s s {'e': 0.5, 'i': 0.5}\n",
      "s u {'n': 1.0}\n",
      "s z {'u': 1.0}\n",
      "s,  {'a': 1.0}\n",
      "sag {'t': 1.0}\n",
      "sat {'z': 1.0}\n",
      "sbü {'r': 1.0}\n",
      "sch {'e': 0.14285714285714285, 'l': 0.14285714285714285, 'i': 0.14285714285714285, 'a': 0.14285714285714285, 'o': 0.2857142857142857, 's': 0.14285714285714285}\n",
      "sdr {'u': 1.0}\n",
      "sei {'n': 1.0}\n",
      "sel {'l': 1.0}\n",
      "sen {' ': 1.0}\n",
      "ser {' ': 0.75, 'e': 0.25}\n",
      "sic {'h': 1.0}\n",
      "sie {' ': 0.8333333333333334, 'r': 0.16666666666666666}\n",
      "sin {'d': 1.0}\n",
      "siv {' ': 1.0}\n",
      "sna {'h': 1.0}\n",
      "sof {'o': 1.0}\n",
      "sol {'a': 1.0}\n",
      "spi {'e': 1.0}\n",
      "sre {'r': 1.0}\n",
      "ss  {'k': 0.2857142857142857, 'n': 0.2857142857142857, 'd': 0.2857142857142857, 's': 0.14285714285714285}\n",
      "sse {'n': 1.0}\n",
      "ssn {'a': 1.0}\n",
      "sst {'s': 1.0}\n",
      "st  {'z': 0.14285714285714285, 'd': 0.2857142857142857, 's': 0.14285714285714285, 'a': 0.2857142857142857, 'u': 0.14285714285714285}\n",
      "st, {' ': 1.0}\n",
      "st. {'\\n': 1.0}\n",
      "st: {' ': 1.0}\n",
      "ste {'h': 0.3333333333333333, 'n': 0.3333333333333333, 'm': 0.3333333333333333}\n",
      "sts {'e': 1.0}\n",
      "sub {'v': 1.0}\n",
      "suc {'h': 1.0}\n",
      "swe {'g': 1.0}\n",
      "t a {'l': 0.25, 'b': 0.25, 'n': 0.25, 'r': 0.25}\n",
      "t b {'i': 1.0}\n",
      "t d {'a': 0.2, 'e': 0.6, 'i': 0.2}\n",
      "t e {'r': 1.0}\n",
      "t g {'e': 1.0}\n",
      "t i {'s': 0.5, 'h': 0.5}\n",
      "t l {'a': 1.0}\n",
      "t n {'a': 0.5, 'i': 0.5}\n",
      "t s {'i': 1.0}\n",
      "t t {'r': 1.0}\n",
      "t u {'n': 1.0}\n",
      "t v {'o': 1.0}\n",
      "t w {'e': 1.0}\n",
      "t z {'w': 0.3333333333333333, 'u': 0.6666666666666666}\n",
      "t – {' ': 1.0}\n",
      "t,  {'a': 0.2, 'd': 0.4, 'b': 0.2, 'w': 0.2}\n",
      "t.\n",
      " {'(': 0.5, '\\n': 0.5}\n",
      "t.  {'S': 1.0}\n",
      "t.) {'\\n': 1.0}\n",
      "t:  {'d': 0.5, 'a': 0.5}\n",
      "taa {'t': 1.0}\n",
      "tan {'e': 1.0}\n",
      "tat {'i': 1.0}\n",
      "te  {'s': 1.0}\n",
      "teh {'t': 1.0}\n",
      "tem {'.': 1.0}\n",
      "ten {'z': 0.3333333333333333, ' ': 0.3333333333333333, '.': 0.3333333333333333}\n",
      "ter {'w': 1.0}\n",
      "tes {' ': 1.0}\n",
      "teu {'e': 1.0}\n",
      "the {'i': 1.0}\n",
      "tik {')': 1.0}\n",
      "tio {'n': 1.0}\n",
      "tis {'c': 1.0}\n",
      "tli {'c': 1.0}\n",
      "tom {'-': 1.0}\n",
      "ton {' ': 1.0}\n",
      "top {'i': 1.0}\n",
      "tro {'t': 0.5, 'f': 0.5}\n",
      "tsb {'ü': 1.0}\n",
      "tse {'i': 1.0}\n",
      "tst {'e': 1.0}\n",
      "tt  {'b': 1.0}\n",
      "tz  {'z': 1.0}\n",
      "tzd {'e': 1.0}\n",
      "tzi {'e': 1.0}\n",
      "tät {' ': 1.0}\n",
      "tür {'l': 1.0}\n",
      "u e {'r': 1.0}\n",
      "u r {'e': 1.0}\n",
      "ubi {'o': 1.0}\n",
      "ubv {'e': 1.0}\n",
      "uch {' ': 0.6666666666666666, 'b': 0.16666666666666666, 't': 0.16666666666666666}\n",
      "uck {' ': 1.0}\n",
      "uer {'n': 0.5, ',': 0.5}\n",
      "uf  {'d': 1.0}\n",
      "uin {'e': 1.0}\n",
      "um  {'B': 1.0}\n",
      "unb {'r': 1.0}\n",
      "und {' ': 0.6666666666666666, 'e': 0.3333333333333333}\n",
      "ung {'e': 0.6666666666666666, ' ': 0.3333333333333333}\n",
      "uns {'r': 0.2857142857142857, ' ': 0.2857142857142857, 'e': 0.42857142857142855}\n",
      "unt {'e': 1.0}\n",
      "ur  {'I': 0.16666666666666666, 'g': 0.16666666666666666, 'S': 0.16666666666666666, 'u': 0.16666666666666666, 'P': 0.3333333333333333}\n",
      "urc {'h': 1.0}\n",
      "usd {'r': 1.0}\n",
      "uss {' ': 0.8, 't': 0.2}\n",
      "ute {'n': 1.0}\n",
      "v i {'n': 1.0}\n",
      "ver {'s': 1.0}\n",
      "von {' ': 1.0}\n",
      "wah {'r': 1.0}\n",
      "wan {'d': 1.0}\n",
      "war {'t': 1.0}\n",
      "was {' ': 1.0}\n",
      "wec {'k': 1.0}\n",
      "weg {'e': 1.0}\n",
      "wen {'n': 1.0}\n",
      "wer {'d': 1.0}\n",
      "wir {'d': 1.0}\n",
      "woh {'i': 1.0}\n",
      "wol {'l': 1.0}\n",
      "wus {'s': 1.0}\n",
      "wäh {'l': 1.0}\n",
      "xis {'t': 1.0}\n",
      "yst {'e': 1.0}\n",
      "z i {'n': 1.0}\n",
      "z z {'u': 1.0}\n",
      "zah {'l': 1.0}\n",
      "zde {'m': 1.0}\n",
      "zei {' ': 1.0}\n",
      "zep {'t': 1.0}\n",
      "zie {'h': 1.0}\n",
      "zu  {'e': 0.5, 'r': 0.5}\n",
      "zum {' ': 1.0}\n",
      "zur {' ': 1.0}\n",
      "zwe {'c': 1.0}\n",
      "ähl {'t': 1.0}\n",
      "ät  {'–': 1.0}\n",
      "ück {' ': 0.5, '.': 0.5}\n",
      "üge {'n': 1.0}\n",
      "ügt {' ': 1.0}\n",
      "üll {'.': 1.0}\n",
      "ürg {'e': 1.0}\n",
      "ürl {'i': 1.0}\n",
      "– D {'i': 1.0}\n",
      "– w {'a': 1.0}\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "vocabulary={}\n",
    "for i in range(len(txt) -n):\n",
    "    key = txt[i:i+n]\n",
    "    value = txt[i+n]\n",
    "    # Check if the key exists.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value.\n",
    "        vocabulary[key].append(value)\n",
    "    # Else insert a new key + value.\n",
    "    else:\n",
    "        vocabulary[key] = [value]\n",
    "        \n",
    "''' Calculate the probability. '''\n",
    "\n",
    "for key, value in vocabulary.items():\n",
    "    length = len(vocabulary[key])\n",
    "    temporary_dic = {}\n",
    "    for char in value:\n",
    "        if(char not in temporary_dic.keys()):\n",
    "            temporary_dic[char] = 1\n",
    "        else:\n",
    "            temporary_dic[char] += 1   \n",
    "    # Uncomment the next line to show all probabilities.\n",
    "#     print(key, temporary_dic)\n",
    "            \n",
    "    for _keys,amount in temporary_dic.items():\n",
    "        temporary_dic[_keys] = (amount/length)\n",
    "    vocabulary[key] = temporary_dic\n",
    "\n",
    "for key in sorted(vocabulary):\n",
    "    print (key, vocabulary[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to pick the next token based on our dictionary, with probabilities as their weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Return a randomly selected token from our list of options. '''\n",
    "\n",
    "def next_token(key):\n",
    "\n",
    "    # Check if key is included in the vocabulary.\n",
    "    if not key in vocabulary.keys():\n",
    "        # If not, pick a random key from the vocabulary.\n",
    "        key = random.choice(list(vocabulary.keys()))\n",
    "\n",
    "    # Otherwise we'll use the key given as argument.\n",
    "    \n",
    "    # Return the next token for the key.\n",
    "    # The [0] in the end is because the random choice based on probability returns a list.\n",
    "    return random.choices(list(vocabulary[key].keys()), weights=vocabulary[key].values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate n-order random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "– Die POESIE und unden.)\n",
      "\n",
      "– Die da unbrauer, dass dieser proffen.)\n",
      "\n",
      "– Die POESIE kann: Glück.)\n",
      "\n",
      "– Die POESIE wahrungen er Glück.)\n",
      "\n",
      "– Die Welt zu recken.\n",
      "(Lebendig.)\n",
      "\n",
      "– Die sein mit ers ist der proffen.\n",
      "(Regiert d\n"
     ]
    }
   ],
   "source": [
    "''' Generate text. '''\n",
    "\n",
    "generated_text = '– Die POESIE'\n",
    "\n",
    "for i in range(200):\n",
    "    generated_text += next_token(generated_text[-n:])\n",
    "    \n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
